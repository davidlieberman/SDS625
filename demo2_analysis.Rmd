---
title: "Hartford Crime and Property Value Analysis"
author: "Quan Le, David Lieberman, Lisa Lin"
date: "2024-09-25"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)    # Plots
library(plotly)     # Interactive plots
library(sf)         # Polygons
library(GGally)     # Pairwise correlation plots
library(tigris)     # Census data
library(data.table) # Faster data manipulation
library(dplyr)      # Data manipulation
library(tidyr)      # Data manipulation
library(ks)         # Kernel density estimation

setDTthreads(threads = 0)

options(tigris_use_cache = TRUE)
options(tigris_year = 2021)
```


## Preprocessing

Since the data is so large, we prepare some filters and computations in advance and load the processed data. 

The filters applied to the data are:

* Single family homes only
* Crimes from 2016-2021 since the assessed property values are from 2021, and we deem crimes prior to 2016 to be less relevant to the current property values

Within the crime data, we filter out major property crimes (robberies, burglaries, larceny, or theft) and violent crimes (assaults, homicides, shootings).

The thefts and violent crimes data is then aggregated spatially in two ways:

1. Count the number of crimes within 150 meters of each parcel
2. Compute kernel density estimation of crimes within a bandwidth of each parcel, where bandwidth is selected via cross-validation

```{r preprocessing}
# # Aggregate crime data spatially in two ways:
# # 1. Count number of crimes within 150 meters of each parcel
# # 2. Compute kernel density estimation of crimes within 150 meters of each 
# #    parcel
# # Filter major property crimes and violent crimes
# stealin <- z[grep("ROBBERY|BURGLARY|LARCENY|THEFT",
#                    z$UCR_1_Category), ]
# hurtin <- z[grep("ASSAULT|HOMICIDE|SHOOTING", z$UCR_1_Category), ]
# # Get number of thefts and violent crimes within 150 meters of each parcel
# p$Thefts <- st_is_within_distance(st_transform(p, crs = 26956),
#                                   st_transform(stealin, crs = 26956),
#                                   dist = units::set_units(150, "m")) |>
#   sapply(length)
# p$Violence <- st_is_within_distance(st_transform(p, crs = 26956),
#                                     st_transform(hurtin, crs = 26956),
#                                     dist = units::set_units(150, "m")) |>
#   sapply(length)
# # Compute KDE of thefts and violent crimes
# # Bandwidth selection using cross-validation (Hscv)
# p_proj <- p |> st_transform(crs = 26956) |> st_centroid() |> st_coordinates()
# v_proj <- hurtin |> st_transform(crs = 26956) |> st_coordinates()
# p$Violence_KDE <- kde(v_proj, Hscv(v_proj)) |> predict(x = p_proj)
# t_proj <- stealin |> st_transform(crs = 26956) |> st_coordinates()
# p$Thefts_KDE <- kde(t_proj, Hscv(t_proj)) |> predict(x = p_proj)
# 
# # Save parcel data with computed crime statistics
# st_write(p, ".//data//parcel_hartford_single_family_crimestats.geojson")
```


```{r data}
# Read in filtered Hartford crime and parcel data
z <- st_read(".//data//crime_hartford_2016_2021.geojson")
p <- st_read(".//data//parcel_hartford_single_family_crimestats.geojson")

# Get polygons for Hartford's census tracts
hartford_tracts <- st_filter(tracts(state = "CT"),
                             subset(county_subdivisions(state = "CT"), 
                                    NAMELSAD == "Hartford town"),
                             .predicate = st_within) |>
   st_transform(crs = st_crs(z))

# Re-order condition description of parcels
p$Condition_Description <- factor(
  as.character(p$Condition_Description), 
  levels = c("Dilapidated", "Very Poor", "Poor", "Fair", "Fair-Avg", "Average", 
             "Avg-Good", "Good", "Good-VG", "Very Good", "Excellent"))

# Select predictors and filter out NA's
X <- p[, c("OBJECTID", "Assessed_Total", 
           "Thefts", "Violence", "Thefts_KDE", "Violence_KDE", 
           "Living_Area", "Effective_Area", "AYB", 
           "Number_of_Bedroom", "Number_of_Baths", 
           "Condition_Description")] %>%
  rename(Price = Assessed_Total, Year = AYB, 
         Bed = Number_of_Bedroom, Bath = Number_of_Baths,
         Condition = Condition_Description) %>%
  na.omit()
# Check that we haven't dropped too many rows
nrow(p) # 7239 rows
nrow(X) # 7220 rows
```

## Visualization

The manually curated variables are:

* `Price`: Assessed total value of the parcel
* `Thefts`: Number of thefts within 150 meters of the parcel
* `Violence`: Number of violent crimes within 150 meters of the parcel
* `Thefts_KDE`: Kernel density estimation of thefts
* `Violence_KDE`: Kernel density estimation of violence
* `Living_Area`: Living area of the parcel
* `Effective_Area`: Effective area of the parcel
* `Year`: Approximate year the parcel was built
* `Bed`: Number of bedrooms in the parcel
* `Bath`: Number of bathrooms in the parcel

The highly correlated numeric covariates are 

* Thefts and Violence
* Living Area and Effective Area
* Bed and Bath

Overall, there does not seem to be a strong correlation between A couple numeric covariates appear to be correlated with the condition of the parcel:

* Thefts and Violence. There appear to be more thefts and violent crimes near single family homes in `dilapidated` condition. The median thefts near parcels in very poor condition calculated by KDE is relatively higher than the median calculated by counts.
* Year. There appears to be a quadratic relationship between the year a parcel was built and its condition. The median years that parcels were built for those in dilapidated and very poor condition tend to be earlier than parcels in better condition, suggesting that older homes are more likely to be in worse condition. However, there are also older homes in good condition, and homes in average condition have the most recent median year built.

All covariates appear to correlate with the response variable, `Assessed_Total`.

```{r plots, fig.width = 10, fig.height = 8}
# Plot pairwise correlation between numeric predictors
ggpairs(X, columns = c(2:10), lower = list(continuous = "points"), 
        progress = F) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot boxplots of numeric predictors with respect to condition description
# Pivot data longer so that we can facet by variable
LX <- X %>%
  pivot_longer(cols = c(Thefts, Violence, Thefts_KDE, Violence_KDE,
                        Living_Area, Effective_Area, 
                        Year, Bed, Bath, Price), 
               names_to = "variable", values_to = "value")
ggplot(data = LX, aes(x = variable, y = value)) + 
  geom_boxplot(aes(fill = Condition), position = position_dodge(1)) + 
  facet_wrap( ~ variable, scales = "free", ) + 
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(),
        axis.ticks.x = element_blank(), panel.grid.major.x = element_blank(),
        axis.title.y = element_blank())
```

## Analysis

#### 1. Crime counts

We first consider the `Thefts` and `Violence` variables computed by counting crime occurrences within a 150-meter radius of a parcel.

*Variable Selection.* We leave out `Thefts` since it is highly correlated with `Violence` but has a lower correlation with `Price` than `Violence` does. For similar reasons, we leave out `Effective_Area` and keep `Living_Area`. We keep both `Bed` and `Bath` for now.

*Transformations.* From the correlation plots, we can see that `Price`, `Living_Area`, and `Violence` are right-skewed. To adjust for this, we take the log of `Price` and the square root of `Living_Area` and `Violence`. The residual plots look much better for the transformed model.

```{r models1, fig.width = 6, fig.height = 6}
# Fit linear models with no transformations
m0 <- lm(Price ~ Violence + Living_Area + Year + Bed + Bath + Condition, 
         data = X)
summary(m0)
# Plot diagnostics
par(mfrow = c(2, 2))
plot(m0)

# Fit linear models with transformations
m1 <- lm(log(Price) ~ sqrt(Violence) + sqrt(Living_Area) + Year + 
           Bed + Bath + Condition, 
         data = X)
summary(m1)
plot(m1)
```

There are 31 parcels beyond 4 standard errors below the regression line. This means the model is severely overestimating the value of these parcels. Let's find out what these parcels are.

* Geography: There is a cluster of 19 offending parcels near (-72.7, 41.75) in Census Tract 5049. The remaining parcels are scattered throughout Hartford. Interact with the map to see the details of each parcel.
* Condition: The "large" residuals occur for parcels in better than `Average` condition, although the majority of them are `Average` or worse.
* Numeric covariates: The residuals are highly correlated with the living area and number of bedrooms. 

*Solutions.* We try the following fixes:

* Log transform living area: Refer to the previous correlation plots and observe that Price and Living Area appear to have a strongly correlated linear correlation. However, we performed a `log` transformation on the Price variable but a square-root transformation on the Living Area variable. This asymmetry may be the cause of the large residuals.

* Drop number of bedrooms: The number of bedrooms is highly correlated with the residuals, and we might infer that most of the information provided by this variable is already captured in the number of bathrooms.

* Drop the 19 parcels: These parcels are in a small geographic area and may be subject to some unobserved spatial effect.

```{r residuals1, warning = F, fig.width = 10, fig.height = 8}
# Investigate the large negative residuals
r <- residuals(m1) / summary(m1)$sigma # standard residuals
o <- X[r < -4, ]
o$StdResid <- r[r < -4]
nrow(o)

# Add a tooltip label for parcels
o <- o %>% mutate(label = paste0('Price: ', round(Price), '<br>',
                                 'Year: ', Year, '<br>',
                                 'Condition: ', Condition, '<br>',
                                 'Living Area: ', Living_Area, '<br>',
                                 'Bedrooms: ', Bed, '<br>', 
                                 'Bathrooms: ', Bath, '<br>',
                                 'Violence: ', Violence
                                 ))
# Plot the offending parcels geographically
g <- ggplot(o) +
  geom_sf(data = hartford_tracts, aes(text = NAME)) +
  geom_sf(data = o, 
          aes(text = label)) +
  stat_sf_coordinates(size = 1, color = "red") +
  labs(x = "Latitude", y = "Longitude") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
toWebGL(ggplotly(g))

# Plot residuals vs. Condition
# Function for number of observations 
give.n <- function(x){
  return(data.frame(
    y = quantile(x, .75) + 0.1, 
    label = paste0("n = ", length(x))
    ))
}
ggplot(data = o, aes(x = Condition, y = StdResid)) + 
  geom_boxplot() + 
  stat_summary(fun.data = give.n, geom = "text", fun.y = median) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme_bw()

# Plot residuals vs transformed numeric covariates
o <- o %>%
  mutate(logPrice = log(Price), 
         sqrtViolence = sqrt(Violence),
         sqrtLiving_Area = sqrt(Living_Area))
ggpairs(o, columns = c("StdResid", "sqrtViolence", "sqrtLiving_Area", 
                       "Year", "Bed", "Bath"), 
        lower = list(continuous = "points"),
        progress = F) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Let's test our hypotheses. 

* After taking the log of `Living_Area`, the residuals are more symmetrically distributed. We may have sacrificed some upper tail normality for the lower tail, since there appear to be more residuals larger than 4 now. However, we have reduced the total number of residuals beyond 4 SE's from 33 to 21. Notice that the `Beds` variable is no longer statistically significant.
* Dropping the number of bedrooms has no noticeable effect on the model.
* Dropping the 19 parcels increases the adjusted $R^2$ to 0.76 and further decreases the number of residuals beyond 4 SE's to 5. Thus, these parcels represented a significant source of error in the model and might be a good point of further investigation.

```{r models2, fig.width = 6, fig.height = 6}
# Take log of living area
m2 <- lm(log(Price) ~ sqrt(Violence) + log(Living_Area) + Year + 
           Bed + Bath + Condition, 
         data = X)
summary(m2)
par(mfrow = c(2, 2))
plot(m2)

# Drop number of bedrooms
m3 <- lm(log(Price) ~ sqrt(Violence) + log(Living_Area) + Year + 
           Bath + Condition, 
         data = X)
summary(m3)
plot(m3)

# Drop the 19 outlier parcels
XO <- X[!X$OBJECTID %in% o$OBJECTID, ]
m4 <- lm(log(Price) ~ sqrt(Violence) + log(Living_Area) + Year + 
           Bath + Condition, 
         data = XO)
summary(m4)
plot(m4)

# Compare residuals beyond 4 SE's
r1 <- residuals(m1) / summary(m1)$sigma
sum(r1 < -4 | r1 > 4)
r3 <- residuals(m3) / summary(m3)$sigma
sum(r3 < -4 | r3 > 4)
r4 <- residuals(m4) / summary(m4)$sigma
sum(r4 < -4 | r4 > 4)
```

#### 2. Crime KDE

Replacing the `Violence` computed by counts with `Violence_KDE` computed by kernel density estimation increases the adjusted $R^2$ and reduces residual standard error. From the plots, there is not a substantial change in the residuals. Thus, we can conclude that the KDE of violent crimes is a better predictor of property value than the count of violent crimes. Our final model is:

$$
\log \text{Price} = \beta_0 + \beta_1 \sqrt{\text{Violence_KDE}} + \beta_2 \log(\text{Living_Area}) + \beta_3 \text{Year} + \beta_4 \text{Bath} + \beta_5 \text{Condition}
$$

```{r models3, fig.width = 6, fig.height = 6}
m5 <- lm(log(Price) ~ sqrt(Violence_KDE) + log(Living_Area) + Year + 
           Bath + Condition, 
         data = XO)
summary(m5)
par(mfrow = c(2, 2))
plot(m5)
```



## References

Spatial regression 

https://oerstatistics.wordpress.com/wp-content/uploads/2016/03/intro_to_r.pdf#page=68.08

https://crd230.github.io/lab8.html

Kernel density estimation

https://seeing-statistics.com/issue4/



