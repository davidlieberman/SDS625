---
title: "9-25-2024 Methods"
author: "Lisa Lin"
date: "2024-09-25"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(plotly)
library(sf)
library(tigris)
library(data.table)
library(dplyr)
library(tidyr)

# here::i_am(".git/config")
# knitr::opts_chunk$set("root.dir" = here::here("HW3"))
# knitr::opts_chunk$set(eval = FALSE)
# knitr::opts_chunk$set(message = FALSE)
setDTthreads(threads = 0)

options(tigris_use_cache = TRUE)
options(tigris_year = 2021)
```

## Data Processing

```{r, eval = FALSE}
# Get crime data from ArcGIS API and remove (4) entries with missing geometry
# Write cleaned data to GeoJSON file
# crime_dg <- st_read("https://utility.arcgis.com/usrsvcs/servers/3adad6320b7a421bb3826ec8871e2b66/rest/services/OpenData_PublicSafety/MapServer/2/query?outFields=*&where=1%3D1&f=geojson")
# crime_dg$Date <- as.Date(fread(".//data//crime_dg.csv")$Date, "%Y/%m/%d")
# crime_dg <- crime_dg[!st_is_empty(crime_dg),]
# st_write(crime_dg, ".//data//crime_dg.geojson")

# Read in Hartford crime and parcel data
# c <- st_read(".//data//crime_dg.geojson")
# p <- st_read(".//data//parcel_hartford.geojson")

# Filter parcels for single family homes only
# Entire apartment or residential complexes are bought less frequently 
# and are more complicated to appraise.
# resid_labels <- c("ONE FAMILY") #, "TWO FAMILY", "THREE FAMILY")
# pr <- p[p$State_Use_Description %in% resid_labels, ]

# Filter crimes from 2016-2021
# Property appraisal was made in 2021.
# Assume that about 5 years of crime data is sufficient to capture the effect
# of crime on property values if any effect exists.
# cc <- c[as.Date(c$Date) >= as.Date("2016-01-01") & 
#           as.Date(c$Date) <= as.Date("2021-12-31"),]

# Save filtered data
# st_write(pr, ".//data//parcel_hartford_single_family.geojson")
# st_write(cc, ".//data//crime_hartford_2016_2021.geojson")
```

```{r data}
# Read in filtered Hartford crime, parcel, and population data
z <- st_read(".//data//crime_hartford_2016_2021.geojson")
p <- st_read(".//data//parcel_hartford_single_family.geojson")
pop <- read.csv(".//data//population_by_tract.csv", skip = 3, header = T)[,1:3]

# Get polygons for Hartford's census tracts
hartford_tracts <- st_filter(tracts(state = "CT"),
                             subset(county_subdivisions(state = "CT"), 
                                    NAMELSAD == "Hartford town"),
                             .predicate = st_within) |>
   st_transform(crs = st_crs(z))

# Get polygons for Hartford's bodies of water 
water <- st_intersection(
  st_transform(area_water("CT", "Hartford"), crs = st_crs(hartford_tracts)), 
  hartford_tracts)
```

## Data Exploration

The filters applied to the data are:

* Single family homes only
* Crimes from 2016-2021 since the assessed property values are from 2021, and we deem crimes prior to 2016 to be less relevant to the current property values

The manually curated variables are:

* `Price`: Assessed total value of the parcel
* `Thefts`: Number of thefts (robberies, burglaries, larceny, theft, or stolen property) within 0.1 miles of the parcel
* `Violence`: Number of violent crimes (assaults, homicides, shootings) within 0.1 miles of the parcel
* `Living_Area`: Living area of the parcel
* `Effective_Area`: Effective area of the parcel
* `Year`: Approximate year the parcel was built
* `Bed`: Number of bedrooms in the parcel
* `Bath`: Number of bathrooms in the parcel

The highly correlated numeric covariates are 

* Thefts and Violence
* Living Area and Effective Area
* Bed and Bath

There appear to be more thefts and violent crimes near single family homes in `dilapidated` condition. Homes in worse condition tend to be older, but there are also older homes in good condition.

There is not a clear relationship between the year the parcel was built and its condition. 

All covariates appear to correlate with the response variable, `Assessed_Total`.

```{r plots, fig.width = 10, fig.height = 8}
# install.packages("GGally")
library(GGally)

# Filter major property crimes and violent crimes
stealin <- z[grep("ROBBERY|BURGLARY|LARCENY|THEFT", 
                   z$UCR_1_Category), ]
hurtin <- z[grep("ASSAULT|HOMICIDE|SHOOTING", z$UCR_1_Category), ]

# Get number of thefts and violent crimes within 0.1 miles of each parcel
p$thefts <- sapply(
  st_is_within_distance(p, stealin, dist = units::set_units(0.1, "mi")),  
  length)
p$violence <- sapply(
  st_is_within_distance(p, hurtin, dist = units::set_units(0.1, "mi")), 
  length)
# Re-order condition description of parcels
p$Condition_Description <- factor(
  as.character(p$Condition_Description), 
  levels = c("Dilapidated", "Very Poor", "Poor", "Fair", "Fair-Avg", "Average", 
             "Avg-Good", "Good", "Good-VG", "Very Good", "Excellent"))

# Select predictors and filter out NA's
X <- p[, c("OBJECTID", "Assessed_Total", "thefts", "violence", "Living_Area", 
           "Effective_Area", "AYB", "Number_of_Bedroom", "Number_of_Baths", 
           "Condition_Description")] %>%
  rename(Price = Assessed_Total, Thefts = thefts, Violence = violence,
         Year = AYB, Bed = Number_of_Bedroom, Bath = Number_of_Baths,
         Condition = Condition_Description) %>%
  na.omit()
# Check that we haven't dropped too many rows
nrow(p) # 7239 rows
nrow(X) # 7220 rows

# Plot pairwise correlation between numeric predictors
ggpairs(X, columns = c(2:9), lower = list(continuous = "points")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Plot boxplots of numeric predictors with respect to condition description
# Pivot data longer so that we can facet by variable
LX <- X %>%
  pivot_longer(cols = c(Thefts, Violence, Living_Area, Effective_Area, 
                        Year, Bed, Bath, Price), 
               names_to = "variable", values_to = "value")
ggplot(data = LX, aes(x = variable, y = value)) + 
  geom_boxplot(aes(fill = Condition), position = position_dodge(1)) + 
  facet_wrap( ~ variable, scales = "free") + 
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(),
        axis.ticks.x = element_blank(), panel.grid.major.x = element_blank(),
        axis.title.y = element_blank())
```

## Analysis

*Variable Selection.* We leave out `Thefts` since it is highly correlated with `Violence` but has a lower correlation with `Price` than `Violence` does. For similar reasons, we leave out `Effective_Area` and keep `Living_Area`. We keep both `Bed` and `Bath` for now.

*Transformations.* From the correlation plots, we can see that `Price`, `Living_Area`, and `Violence` are right-skewed. To adjust for this, we take the log of `Price` and the square root of `Living_Area` and `Violence`. 

```{r models1, fig.width = 6, fig.height = 6}
# Fit linear models with no transformations
m0 <- lm(Price ~ Violence + Living_Area + Year + Bed + Bath + Condition, 
         data = X)
summary(m0)
# Plot diagnostics
par(mfrow = c(2, 2))
plot(m0)

# Fit linear models with transformations
m1 <- lm(log(Price) ~ sqrt(Violence) + sqrt(Living_Area) + Year + 
           Bed + Bath + Condition, 
         data = X)
summary(m1)
plot(m1)
```

There are many parcels beyond 4 standard errors below the regression line. This means the model is severely overestimating the value of these parcels. Let's find out what these parcels are.

* Geography: There is a cluster of offending parcels near (-72.7, 41.75). The remaining parcels are scattered throughout Hartford.
* Condition: The "large" residuals occur for parcels in better than `Average` condition, although the majority of them are `Average` or worse.
* Numeric covariates: The residuals are highly correlated with the living area and number of bedrooms. 

*Solution.* Refer to the previous correlation plots and observe that Price and Living Area appear to have a strongly correlated linear correlation. However, we performed a `log` transformation on the Price variable but a square-root transformation on the Living Area variable. This asymmetry may be the cause of the large residuals.

```{r residuals1, warning = F, fig.width = 10, fig.height = 8}
# Investigate the large negative residuals
r <- residuals(m1) / summary(m1)$sigma # standard residuals
o <- X[r < -4, ]
o$StdResid <- r[r < -4]
nrow(o)

# Plot the offending parcels geographically
g <- ggplot(o) +
  geom_sf(data = hartford_tracts) +
  geom_sf(data = o) +
  stat_sf_coordinates(size = 1, color = "red") +
  labs(x = "Latitude", y = "Longitude") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
toWebGL(ggplotly(g))

# Plot residuals vs. Condition
# Function for number of observations 
give.n <- function(x){
  return(data.frame(
    y = quantile(x, .75) + 0.1, 
    label = paste0("n = ", length(x))
    ))
}
ggplot(data = o, aes(x = Condition, y = StdResid)) + 
  geom_boxplot() + 
  stat_summary(fun.data = give.n, geom = "text", fun.y = median) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme_bw()

# Plot residuals vs transformed numeric covariates
o <- o %>%
  mutate(logPrice = log(Price), 
         sqrtViolence = sqrt(Violence),
         sqrtLiving_Area = sqrt(Living_Area))
ggpairs(o, columns = c(12:15,7:9), lower = list(continuous = "points"),
        progress = F) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Let's test our hypothesis. 

* After taking the log of `Living_Area`, the residuals are more symmetrically distributed. We may have sacrificed some upper tail normality for the lower tail, since there appear to be more residuals larger than 4 now. However, we have reduced the total number of residuals beyond 4 SE's from 33 to 21. 
* Dropping the number of bedrooms slightly increases adjusted $R^2$.

```{r models2, fig.width = 6, fig.height = 6}
# Take log of living area
m2 <- lm(log(Price) ~ sqrt(Violence) + log(Living_Area) + Year + 
           Bed + Bath + Condition, 
         data = X)
summary(m2)
par(mfrow = c(2, 2))
plot(m2)

# Drop number of bedrooms
m3 <- lm(log(Price) ~ sqrt(Violence) + log(Living_Area) + Year + 
           Bath + Condition, 
         data = X)
summary(m3)
plot(m3)

# Compare residuals beyond 4 SE's
r1 <- residuals(m1) / summary(m1)$sigma
sum(r1 < -4 | r1 > 4)
r3 <- residuals(m3) / summary(m3)$sigma
sum(r3 < -4 | r3 > 4)
```

Repeating the same residuals analysis from before, we see that there are no longer any strongly correlated covariates with the residuals. 

```{r residuals2, warning = F, fig.width = 10, fig.height = 8}
# Investigate the large negative residuals
r <- residuals(m3) / summary(m3)$sigma # standard residuals
o <- X[r < -4, ]
o$StdResid <- r[r < -4]
nrow(o)

# Plot the offending parcels geographically
g <- ggplot(o) +
  geom_sf(data = hartford_tracts) +
  geom_sf(data = o) +
  stat_sf_coordinates(size = 1, color = "red") +
  labs(x = "Latitude", y = "Longitude") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
toWebGL(ggplotly(g))

# Plot residuals vs. Condition
# Function for number of observations 
give.n <- function(x){
  return(data.frame(
    y = quantile(x, .75) + 0.1, 
    label = paste0("n = ", length(x))
    ))
}
ggplot(data = o, aes(x = Condition, y = StdResid)) + 
  geom_boxplot() + 
  stat_summary(fun.data = give.n, geom = "text", fun.y = median) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme_bw()

# Plot residuals vs transformed numeric covariates
o <- o %>%
  mutate(logPrice = log(Price), 
         sqrtViolence = sqrt(Violence),
         logLiving_Area = log(Living_Area))
ggpairs(o, columns = c(12:15,7,9), lower = list(continuous = "points"),
        progress = F) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```





## Other stuff

```{r, fig.width=10, fig.height=8}
# Y <- X[, 2:9] %>%
#   mutate(logPrice = log(Price), 
#          logLiving_Area = log(Living_Area),
#          logYear = log(Year),
#          sqrtBath = sqrt(Bath),
#          sqrtViolence = sqrt(Violence)) %>%
#   select(logPrice, logLiving_Area, Living_Area, logYear, Year, 
#          sqrtBath, Bath, sqrtViolence, Violence)
# ggpairs(Y, columns = c(1:9), lower = list(continuous = "points"),
#         progress = F) +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r, fig.width=6, fig.height=6}
# Try no transformation on Violence
# m4 <- lm(log(Price) ~ Violence + log(Living_Area) + Year + 
#            Bath + Condition, 
#          data = X)
# summary(m4)
# par(mfrow = c(2, 2))
# plot(m4)
# 
# r1 <- residuals(m4) / summary(m4)$sigma
# sum(r1 < -4 | r1 > 4)
```

```{r}
# Rename tract columns to distinguish from parcel and crime data
# hartford_tracts <- hartford_tracts %>%
#   rename(tract_geometry = geometry, tract_name = NAME, tract_id = GEOID)

# # Extract year from crime date
# c$year <- year(as.Date(c$Date))

# # Join parcel and crime data to census tracts (keep tract geometry)
# tp <- st_join(hartford_tracts, p)
# tc <- st_join(hartford_tracts, c)

# # Extract short tract name from in population data to match tract polygons
# pop$tract_name <- gsub("[^0-9.]", "", pop$Census.Tract)

# # Calculate average housing price by census tract
# ap <- tp %>%
#   group_by(tract_name) %>%
#   summarise(avg_house_value = mean(Assessed_Total, na.rm = TRUE))
# 
# # Calculate crime rate by census tract and year
# at <- tc[1:1000,] %>% 
#   group_by(tract_name, year) %>%
#   summarise(crime_count = n()) %>%
#   left_join(pop, by = "tract_name") %>%
#   mutate(crime_rate_per_1000 = crime_count / Estimated.Population * 1000) %>%
#   select(tract_name, year, crime_rate_per_1000) %>%
#   pivot_wider(names_from = year, values_from = crime_rate_per_1000) %>%
#   left_join(ap, by = "tract_name") %>%
#   select(tract_name, everything()) 
# 
#   write.csv(".//data//crime_rate_by_tract.csv", row.names = FALSE)
# 
# tc

```

```{r}
# library(glmnet)

# # Format predictors and response variable from parcel data
# X <- p %>%
#   dplyr::select(Condition_Description, 
#                 AYB, Living_Area, Effective_Area, 
#                 Total_Rooms, Number_of_Bedroom, Number_of_Baths,
#                 thefts, violence) %>%
#   # mutate(sqrt_Living_Area = sqrt(Living_Area),
#   #        sqrt_Effective_Area = sqrt(Effective_Area),
#   #        thefts1 = thefts + 1,
#   #        thefts2 = thefts*2) %>%
#   sf::st_drop_geometry()
# X <- data.matrix(X)
# y <- p$Assessed_Total

# # Remove rows with missing values
# w <- complete.cases(X, y)
# X <- X[w, ]
# y <- y[w]

# # Select variables
# # Run lasso regression 
# cv_tune.lasso_model = suppressMessages(suppressWarnings(
#   cv.glmnet(x = X,
#             y = y,
#             nlambda = 1000,
#             nfolds = 500,
#             pmax = 15,
#             parallel = TRUE)))
# 
# plot(cv_tune.lasso_model)
# 
# lasso_modelmin = glmnet(x = X, y = y, lambda = cv_tune.lasso_model$lambda.min)
# lasso_model1se = glmnet(x = X, y = y, lambda = cv_tune.lasso_model$lambda.1se)
# 
# # Does not select Total_Rooms
# coef(lasso_modelmin) 
# # Does not select Total_Rooms, Number_of_Bedroom, thefts
# coef(lasso_model1se)
# 
# vars_keepmin = rownames(coef(lasso_modelmin))[
#   which(as.matrix(coef(lasso_modelmin)) != 0)][-1]
# vars_keep1se = rownames(coef(lasso_model1se))[
#   which(as.matrix(coef(lasso_model1se)) != 0)][-1]
```


```{r}
# # Calculate centroids of parcels and crime
# centroids <- st_centroid(p)
# coords <- st_coordinates(centroids)
# p$centroid.x <- coords[, 'X']
# p$centroid.y <- coords[, 'Y']
# 
# centroids <- st_centroid(c)
# coords <- st_coordinates(centroids)
# c$centroid.x <- coords[, 'X']
# c$centroid.y <- coords[, 'Y']
# 
# 
# # Filter property crimes and violent crimes
# stealin <- c[grep("ROBBERY|BURGLARY|LARCENY|THEFT|STOLEN", 
#                    c$UCR_1_Category), ]
# hurtin <- c[grep("ASSAULT|HOMICIDE|SHOOTING", c$UCR_1_Category), ]
# 
# # Get number of thefts and violent crimes within 0.1 miles of each parcel
# p$thefts <- sapply(
#   st_is_within_distance(p, stealin, dist = units::set_units(0.1, "mi")),  
#   length)
# p$violence <- sapply(
#   st_is_within_distance(p, hurtin, dist = units::set_units(0.1, "mi")), 
#   length)
# 
# st_within(p$geometry[1], p$geometry[1])
# st_within(p$geometry[1], hartford_tracts[1])
```


#### Data Exploration

```{r}
# # For each census tract, get average property value in 2021 and 
# # average annual crime count 
# # Create a new dataframe
# library(dplyr)
# # Add a column for year
# c <- c %>%
#   mutate(year = year(as.Date(Date)))
# # Drop geometry data 
# cc <- sf::st_drop_geometry(c)
# pp <- sf::st_drop_geometry(p)
# 
# # Calculate total crimes per year
# crimes_per_year <- table(cc$year)
# 
# 
# select(year) %>%
#   group_by(year) %>%
#   summarise(total_crime_per_yr = n())
# 
# 
# # Aggregate crime to census level to get crime rate


```


```{r, warning = FALSE}
# # Plot census tracts colored by crime rates and sized by property values
# l1 = leaflet(c_tract) %>%
#   
#   addProviderTiles('CartoDB.Positron') %>%
#   
#   ## census tracts
#   addPolygons(fillColor = ~pal1(rescaled.house.value), 
#               label = ~label %>% lapply(htmltools::HTML), 
#               weight = 0.5,
#               color = 'black',
#               fillOpacity = 0.8) %>%
#   
#   # stops
#   addCircleMarkers(data = ds,
#                    lng = ~stop1_lon,
#                    lat = ~stop1_lat,
#                    label = ~label %>% lapply(htmltools::HTML),
#                    color = pubred,
#                    radius = ~log(`n_to_Grand Central` + `n_to_New Haven`)) %>%
#   
#   setView(lng = -73.3, 
#           lat = 41.21979, 
#           zoom = 10) %>%
#   
#   addTiles()
```


```{r, warning = FALSE}
# # Plot sample of crimes and parcels
# 
# # library(mapview)
# # mapview(dplyr::sample_n(c, 1e3), dplyr::sample_n(p, 1e3))
# 
# g <- ggplot(dplyr::sample_n(c, 1e3)) +
#    geom_sf(data = hartford_tracts) +
#    geom_sf(data = dplyr::sample_n(p, 1e3)) +
#    geom_density_2d(aes(X,Y), data = ~cbind(.x, st_coordinates(.x))) +
#    stat_sf_coordinates(size = 0.1, color = "red") +
#    labs(x = "Latitude", y = "Longitude") +
#    theme_bw()
# 
# p <- toWebGL(ggplotly(g))
# p$x$data[[4]]$hoverinfo <- "none"
# p
```

```{r}
# # Plot average residential parcel value by census tract 
# # with crime counts binned by area
# 
# # Map parcel address to 
# 
# 
# # Get average residential parcel value by census tract
# parcel_dg$Zone
# 
# hartford_tracts
# 
# parcel_dg$avg_residential_value <- parcel_dg$AV_LAND / parcel_dg$AV_TOTAL
```


## References

Spatial regression 

https://oerstatistics.wordpress.com/wp-content/uploads/2016/03/intro_to_r.pdf#page=68.08

https://crd230.github.io/lab8.html

Kernel density estimation

https://seeing-statistics.com/issue4/



